{
  "documents": [
    {
      "doc_id": "kb-2026-02-runbook-redis-evictions",
      "title": "Runbook: Redis Evictions Causing Cart Staleness (cart-service, checkout-service)",
      "document_type": "runbook",
      "created_at": "2026-02-02",
      "content": "# Summary\nRedis eviction spikes (or Redis being temporarily unavailable) can cause carts to appear stale, totals to mismatch between cart-service and checkout-service, and a surge of 409/412 responses during checkout. This runbook covers detection, mitigation, and recovery.\n\n# Affected components\n- **cart-service** (FastAPI, python 3.11, uvicorn)\n- **checkout-service** (FastAPI)\n- **search-api** (indirect: recommendations in cart)\n- **Redis** (clustered, 3 masters + 3 replicas, Redis 7.2.4)\n- **Postgres** (primary source of truth for cart items)\n\n# Symptoms\n## User-facing\n- Cart shows missing items after refresh\n- Checkout fails with:\n  - `409 CART_VERSION_MISMATCH`\n  - `412 PRECONDITION_FAILED`\n- Totals change between cart page and checkout confirmation\n\n## Service metrics\n- cart-service: increased `redis_cache_miss_total`, `redis_errors_total`\n- checkout-service: increased `cart_fetch_fail_total`, `http_409_total`\n- Redis: `evicted_keys` rising, `used_memory` near `maxmemory`\n\n# Quick triage\n## 1) Confirm incident scope\n- Grafana dashboard: **Platform / Redis / Cache Health**\n  - Look at: `evicted_keys`, `connected_clients`, `keyspace_hits`, `keyspace_misses`\n- Service dashboards:\n  - **cart-service / Latency & Errors**\n  - **checkout-service / Checkout funnel**\n\n## 2) Check recent deploys\n- GitHub Actions: last successful deployment to prod for cart-service/checkout-service.\n- If within the last 30 minutes: suspect a regression in cache keying or TTL.\n\n## 3) Validate Redis connectivity from a pod\n`bash\nkubectl -n ecommerce-prod exec -it deploy/cart-service -- sh\npython -c \"import redis; r=redis.Redis(host='redis.ecommerce-prod.svc', port=6379, socket_connect_timeout=1); print(r.ping())\"\n`\nExpected: `True`. If timeout/connection error: go to **Mitigation A**.\n\n# Mitigation\n## Mitigation A: Redis unavailable or high error rate\n1. Enable **cache bypass** for cart reads in cart-service.\n   - Feature flag: `CART_CACHE_BYPASS=true`\n   - Set via config map `cart-service-config` (requires rollout)\n`bash\nkubectl -n ecommerce-prod set env deploy/cart-service CART_CACHE_BYPASS=true\nkubectl -n ecommerce-prod rollout status deploy/cart-service\n`\n2. Confirm cart-service is reading from Postgres only.\n   - Look for log line: `cache=disabled source=postgres`\n3. Watch Postgres load.\n   - If Postgres CPU > 75% or p95 query latency > 200ms, throttle traffic (see **Mitigation D**).\n\n## Mitigation B: Evictions due to maxmemory\n1. Confirm maxmemory policy:\n   - Expected: `allkeys-lfu` (ADR-2025-03-redis-lfu)\n   - If `volatile-ttl` or `noeviction`, notify Infra.\n2. Reduce memory pressure by expiring large keys.\n   - Cart keys pattern: `cart:{user_id}:v{n}`\n`bash\nkubectl -n ecommerce-prod exec -it statefulset/redis-master -- redis-cli --scan --pattern 'cart:*' | head -n 200 | xargs -n 50 redis-cli DEL\n`\n   - Edge case: this will force users to reload carts from Postgres and rehydrate cache. Expect increased DB reads.\n3. Temporarily reduce cache TTL for carts:\n   - Env var: `CART_CACHE_TTL_SECONDS=120` (default 900)\n\n## Mitigation C: Version mismatch storms (409)\n- checkout-service uses optimistic concurrency:\n  - It passes `If-Match: cart_etag` to cart-service.\n- If etags are derived from Redis value and Redis evicts keys, etag may reset.\n1. Enable stable etag derivation from Postgres:\n   - Feature flag: `CART_ETAG_SOURCE=postgres`\n2. Rollout checkout-service.\n\n## Mitigation D: Traffic shaping\nIf DB pressure becomes the primary risk:\n1. Apply rate-limit at ingress for `/api/cart/*` and `/api/checkout/*`.\n2. Prefer 429 over cascading failures.\n\n# Recovery\n## Validate after mitigation\n- cart-service error rate < 1%\n- checkout funnel recovers (conversion within 10% of baseline)\n- Redis `evicted_keys` flat for 10+ minutes\n\n## Re-enable cache (if bypass was set)\n- Only after Redis memory and error rate stabilize.\n`bash\nkubectl -n ecommerce-prod set env deploy/cart-service CART_CACHE_BYPASS-\n`\n\n# Edge cases / pitfalls\n- **Ghost carts**: if a user has multiple sessions, stale local storage can re-submit old cart_id; expect `404 CART_NOT_FOUND`.\n- **Large carts** (> 200 items): serialized cart payload can exceed 1MB; Redis ops may exceed `proto-max-bulk-len` if misconfigured. Symptom: `ERR Protocol error: invalid bulk length`.\n- **Clock drift** on app nodes can break TTL-based reconciliation. Check node time sync if only some pods are affected.\n\n# Post-incident actions\n- Create a ticket to verify maxmemory policies and key sizes.\n- Add alert: `increase(redis_evicted_keys_total[5m]) > 0`.\n- Reference related postmortem: **PM-2025-11-redis-oom**.\n"
    },
    {
      "doc_id": "kb-2026-01-runbook-stripe-webhook-backlog",
      "title": "Runbook: Stripe Webhook Backlog (payment-gateway, checkout-service)",
      "document_type": "runbook",
      "created_at": "2026-01-18",
      "content": "# Summary\nStripe webhook delivery delays can cause orders to remain in `PAYMENT_PENDING`, duplicate fulfillment attempts, or missing refunds. This runbook covers diagnosing webhook backlog, verifying signature validation, and replaying events safely.\n\n# Services and dependencies\n- **payment-gateway** (legacy Node.js 18.19, Express)\n- **checkout-service** (FastAPI)\n- **Postgres** (orders, payments tables)\n- **Redis** (idempotency cache)\n- **Stripe** (API version pinned to 2023-10-16 in payment-gateway)\n\n# Symptoms\n## User-facing\n- Order confirmation page shows pending state for > 2 minutes\n- Refund initiated but status stays `REQUESTED`\n\n## Metrics\n- payment-gateway: `stripe_webhook_queue_depth` increasing\n- payment-gateway: `http_5xx_total` spikes on `/webhooks/stripe`\n- checkout-service: `orders_payment_pending_total` elevated\n\n# Immediate checks\n## 1) Stripe dashboard\n- Check recent webhook attempts for endpoint `https://api.company.tld/webhooks/stripe`.\n- Look for status codes:\n  - `400 invalid_signature`\n  - `429 rate_limited`\n  - `500 internal_error`\n\n## 2) payment-gateway logs\nSearch for:\n- `StripeSignatureVerificationError: No signatures found matching the expected signature for payload`\n- `UnhandledPromiseRejection: Error: connect ETIMEDOUT postgres`\n\n## 3) Validate secret and clock drift\nSignature verification is time-sensitive. If nodes drift, Stripe will still send but our code rejects.\n- Confirm env var: `STRIPE_WEBHOOK_SECRET` matches the one in Stripe dashboard.\n- Check time sync on nodes (Kubernetes node status + NTP).\n\n# Mitigation\n## A) If invalid_signature (400)\n1. Confirm the webhook secret in `payment-gateway` deployment.\n`bash\nkubectl -n ecommerce-prod describe deploy/payment-gateway | grep STRIPE_WEBHOOK_SECRET -n\n`\n2. Validate we are not behind a proxy that alters raw body.\n- payment-gateway must use `express.raw({ type: 'application/json' })` on webhook route.\n- If a recent change added `express.json()` globally before the webhook route, rollback.\n\n## B) If rate-limited (429) from our side\n- We throttle webhook handler with `WEBHOOK_MAX_CONCURRENCY`.\n1. Temporarily increase concurrency from 20 to 50.\n`bash\nkubectl -n ecommerce-prod set env deploy/payment-gateway WEBHOOK_MAX_CONCURRENCY=50\nkubectl -n ecommerce-prod rollout status deploy/payment-gateway\n`\n2. Ensure Postgres can handle the write burst.\n\n## C) If Postgres timeouts\n1. Switch payment-gateway to degraded mode: enqueue events only.\n- Env flag: `WEBHOOK_DEFER_DB_WRITES=true`\n- This stores minimal event data in Redis list `stripe:webhook:deferred`.\n2. Once DB is stable, run the replayer job:\n`bash\nkubectl -n ecommerce-prod create job --from=cronjob/stripe-webhook-replay stripe-webhook-replay-manual\n`\n\n# Safe replay / idempotency\nWe rely on idempotency at two layers:\n- Stripe event id: `evt_*` stored in Postgres `payments.stripe_event_id` (unique index)\n- Redis key: `stripe:evt:{id}` TTL 7 days\n\nIf replaying, verify unique constraint exists:\n`sql\n\\d payments;\n-- expect: unique (stripe_event_id)\n`\n\n# Validation steps\n## Confirm backlog draining\n- `stripe_webhook_queue_depth` should trend downward.\n- Stripe dashboard: attempts should return 2xx.\n\n## Confirm state transitions\nRun queries:\n`sql\nselect status, count(*) from orders where created_at > now() - interval '1 hour' group by 1;\nselect payment_status, count(*) from payments where created_at > now() - interval '1 hour' group by 1;\n`\nExpected: `PAYMENT_PENDING` not growing.\n\n# Edge cases\n- **Duplicate charge events**: Stripe can deliver the same event multiple times. Never assume once-only delivery.\n- **Out-of-order events**: `charge.refunded` can arrive before `payment_intent.succeeded` in rare retries. Our handler must tolerate this by checking current DB state.\n- **Large payloads**: Some events include expanded objects. If ingress has a 1MB limit, it may return 413, causing repeated retries.\n- **Partial deploy**: If only some pods have the correct webhook secret, failures appear intermittent.\n\n# Rollback guidance\nIf a deploy introduced signature failures or 500s:\n- Roll back payment-gateway to last known good image tag, typically `payment-gateway:1.38.2`.\n`bash\nkubectl -n ecommerce-prod rollout undo deploy/payment-gateway\n`\n\n# Related docs\n- ADR-2024-12: Stripe webhooks vs polling\n- PM-2025-08: Webhook retries causing duplicate fulfillment\n"
    },
    {
      "doc_id": "kb-2025-10-runbook-es-cluster-red",
      "title": "Runbook: Elasticsearch Cluster Red / Search Degradation (search-api, indexing-worker)",
      "document_type": "runbook",
      "created_at": "2025-10-07",
      "content": "# Summary\nThis runbook addresses Elasticsearch cluster health issues (yellow/red) leading to degraded search results, timeouts in search-api, and indexing lag. It assumes Elasticsearch 8.11.x deployed on Kubernetes with 3 master-eligible nodes and 6 data nodes.\n\n# Affected components\n- **search-api** (FastAPI)\n- **indexing-worker** (Python Celery worker consuming Kafka topic `catalog.product.changed`)\n- **Elasticsearch** (8.11.3)\n- **Postgres** (source of truth for product catalog)\n\n# Symptoms\n- search-api returns `503 SEARCH_UNAVAILABLE` or `504 upstream timeout`\n- p95 latency > 800ms on `/api/search`\n- Indexing lag: Kafka consumer group `indexing-worker` lag increases\n- Elastic health is `red` or `yellow`\n\n# Initial triage\n## 1) Check cluster health\n`bash\nkubectl -n ecommerce-prod port-forward svc/elasticsearch 9200:9200\ncurl -s http://localhost:9200/_cluster/health?pretty\n`\nKey fields:\n- `status`: green/yellow/red\n- `unassigned_shards`\n\n## 2) Check shard allocation explain\n`bash\ncurl -s -X GET http://localhost:9200/_cluster/allocation/explain?pretty\n`\nLook for:\n- `NODE_LEFT`\n- `disk_threshold`\n- `shards_limit`\n\n## 3) search-api errors\nCommon error snippet:\n- `elasticsearch.exceptions.ConnectionTimeout: Connection timed out`\n- `TransportError(429, 'es_rejected_execution_exception', ...)`\n\n# Mitigation paths\n## A) Disk watermarks (most common)\nIf allocation explain shows disk thresholds:\n1. Check disk usage on data nodes.\n2. Free space by deleting old indices:\n- Daily indices: `products-v3-YYYY.MM.DD`\n- Retention: 14 days\n`bash\ncurl -s -X GET 'http://localhost:9200/_cat/indices/products-v3-*?h=index,store.size,docs.count'\ncurl -s -X DELETE 'http://localhost:9200/products-v3-2025.09.*'\n`\n3. If retention is already enforced, check ILM policy `products-ilm-v3` for failures.\n\n## B) Unassigned primaries after node restart\n1. Confirm node count and pod status.\n`bash\nkubectl -n ecommerce-prod get pods -l app=elasticsearch\n`\n2. If a data node is crashlooping, identify OOM:\n- Check events: `OOMKilled`\n- Consider increasing memory limits (typical: 8Gi -> 12Gi)\n\n## C) Threadpool rejections (429)\nIf you see `es_rejected_execution_exception`:\n1. Reduce search concurrency by enabling circuit breaker in search-api:\n- Env var: `SEARCH_MAX_CONCURRENCY=40` (default 80)\n2. Temporarily disable expensive features:\n- `SEARCH_ENABLE_AGGS=false`\n- `SEARCH_ENABLE_SPELLCHECK=false`\n3. Validate CPU saturation on data nodes.\n\n## D) Indexing runaway\nIf indexing-worker is flooding ES:\n1. Pause consumer group by scaling workers to 0.\n`bash\nkubectl -n ecommerce-prod scale deploy/indexing-worker --replicas=0\n`\n2. Let ES recover.\n3. Resume with lower batch size:\n- `INDEXING_BULK_SIZE=250` (default 1000)\n\n# Recovery\n## Validate green state\n- Cluster health green for 10+ minutes\n- search-api p95 < 250ms\n- No unassigned shards\n\n## Re-enable features\nUndo any temporary flags gradually.\n\n# Edge cases\n- **Mapping explosions**: a product attribute field can become dynamic and create thousands of fields. Symptom: `Limit of total fields [1000] has been exceeded`.\n  - Fix: block dynamic mapping in template `products-template-v3`.\n- **Analyzer mismatch after deploy**: search-api might query a field that changed name. Symptom: `query_shard_exception: failed to find field`.\n  - Fix: deploy index alias compatibility or rollback.\n- **Split brain warnings**: if master pods flap, you may see `master_not_discovered_exception`. In that case, do not force allocate shards until masters stabilize.\n\n# Useful commands\n- Cat shards:\n`bash\ncurl -s 'http://localhost:9200/_cat/shards?v'\n`\n- Hot threads:\n`bash\ncurl -s 'http://localhost:9200/_nodes/hot_threads?pretty'\n`\n\n# Related docs\n- ADR-2025-02: Index aliasing strategy for products\n- PM-2025-12: ES disk watermark incident\n"
    },
    {
      "doc_id": "kb-2025-06-runbook-k8s-rollout-stuck",
      "title": "Runbook: Kubernetes Rollout Stuck / CrashLoopBackOff (FastAPI services)",
      "document_type": "runbook",
      "created_at": "2025-06-21",
      "content": "# Summary\nA deployment rollout can stall due to readiness probe failures, CrashLoopBackOff, or image pull errors. This runbook focuses on FastAPI services (checkout-service, cart-service, search-api) in `ecommerce-prod`.\n\n# Common causes\n- Wrong env vars or missing secrets\n- DB migration mismatch (alembic head not applied)\n- Redis/Elasticsearch DNS issues\n- Readiness probe misconfigured (path or port)\n- OOMKilled due to increased memory usage\n\n# Triage checklist\n## 1) Identify rollout status\n`bash\nkubectl -n ecommerce-prod rollout status deploy/checkout-service\nkubectl -n ecommerce-prod get pods -l app=checkout-service -o wide\n`\nIf it says `waiting for rollout to finish`, inspect failing pods.\n\n## 2) Describe the pod\n`bash\nkubectl -n ecommerce-prod describe pod <pod-name>\n`\nLook for:\n- `ImagePullBackOff`\n- `OOMKilled`\n- `Readiness probe failed`\n- `Back-off restarting failed container`\n\n## 3) Check logs\n`bash\nkubectl -n ecommerce-prod logs <pod-name> --previous\nkubectl -n ecommerce-prod logs <pod-name>\n`\nCommon FastAPI startup failures:\n- `sqlalchemy.exc.OperationalError: could not connect to server: Connection refused`\n- `alembic.util.exc.CommandError: Can't locate revision identified by '...'\n- `pydantic_core.*pydantic_core.ValidationError: 1 validation error for Settings`\n\n# Mitigation by scenario\n## A) Readiness probe failures\nExpected readiness path: `/health/ready`(returns 200 JSON:`{ 'status': 'ok' }`).\n1. Verify probe config:\n- port `8080`\n- initialDelaySeconds `10`\n- timeoutSeconds `2`\n2. Exec into pod and curl locally:\n```bash\nkubectl -n ecommerce-prod exec -it <pod-name> -- sh\nwget -qO- http://127.0.0.1:8080/health/ready\n```\nEdge case: service starts but waits for dependent check (Postgres/Redis). If Redis is down, readiness will fail by design unless `READINESS_STRICT_DEPS=false`.\n\n## B) Missing secrets/config\nSettings are validated at startup. If a required var is missing, pydantic raises.\n1. Compare env var set with expected list in `docs/config/service-env.md`.\n2. Confirm secret exists:\n```bash\nkubectl -n ecommerce-prod get secret checkout-service-secrets\n```\n3. If secret key renamed, roll back or patch.\n\n## C) DB migration mismatch\nIf the container expects a new schema but migrations weren’t applied:\n- Symptom: app crashes on import with missing column.\n- Example: `psycopg.errors.UndefinedColumn: column orders.payment_provider does not exist`\nActions:\n1. Stop the rollout by scaling replicas to previous version (or rollback):\n```bash\nkubectl -n ecommerce-prod rollout undo deploy/checkout-service\n```\n2. Apply migrations via the migration job:\n```bash\nkubectl -n ecommerce-prod create job --from=cronjob/checkout-migrations checkout-migrations-manual\n```\n3. Re-deploy.\n\n## D) OOMKilled\n1. Identify memory usage increase via Grafana: **K8s / Pod Memory**.\n2. Temporarily raise limits:\n- Typical for checkout-service: requests 300Mi, limits 800Mi.\n3. If recent change enabled debug logging or loaded large models, rollback.\n\n## E) ImagePullBackOff\n1. Check image tag exists in registry.\n2. Confirm imagePullSecret is present.\n3. If GitHub Actions pushed to wrong repo, fix pipeline.\n\n# Recovery validation\n- Rollout completes.\n- Error rate stable.\n- p95 latency returns to baseline.\n\n# Edge cases\n- **Partial rollouts**: some pods ready, some failing. This can cause mixed behavior (new code path expects new Redis keys). Prefer rollback quickly.\n- **Stuck terminating**: old ReplicaSet pods hanging due to long shutdown. Increase `terminationGracePeriodSeconds`or fix`lifespan`handlers.\n- **Readiness vs liveness confusion**: do not point liveness at external dependency checks; use a local-only endpoint.\n\n# Related docs\n- Checklist: Production deploy checklist (CL-2025-09-prod-deploy)\n- Postmortem: PM-2025-07-migrations-caused-outage\n"
    },
    {
      "doc_id": "kb-2024-11-runbook-postgres-connection-exhaustion",
      "title": "Runbook: Postgres Connection Exhaustion (too many clients) Across Services",
      "document_type": "runbook",
      "created_at": "2024-11-29",
      "content": "# Summary\nPostgres connection exhaustion manifests as widespread 500s with`FATAL: sorry, too many clients already`. This often occurs after a deploy that increases worker concurrency or when a connection pool misconfiguration disables pooling.\n\n# Services\n- checkout-service (FastAPI + SQLAlchemy 2.0)\n- cart-service (FastAPI)\n- search-api (FastAPI; reads catalog DB for filters)\n- payment-gateway (Node; writes payments and refunds)\n\n# Symptoms\n- Elevated 5xx across multiple services\n- Postgres metrics:\n  - `pg_stat_activity`shows connections near`max_connections`(prod default 600)\n  - CPU may be normal but connections saturate\n- App logs:\n  -`psycopg.OperationalError: connection failed: FATAL: sorry, too many clients already`\n\n# Triage\n## 1) Confirm max connections and current usage\n```sql\nshow max_connections;\nselect count(*) from pg_stat_activity;\nselect usename, application_name, count(*) from pg_stat_activity group by 1,2 order by 3 desc;\n```\nExpected application_name conventions:\n- `checkout-service@<pod>`\n- `cart-service@<pod>`\n- `payment-gateway@<pod>`\n\n## 2) Identify runaway clients\nLook for:\n- many idle in transaction\n- long-running queries holding connections\n```sql\nselect pid, usename, application_name, state, now()-xact_start as xact_age, query\nfrom pg_stat_activity\nwhere state <> 'idle'\norder by xact_age desc\nlimit 20;\n```\n\n# Mitigation\n## A) Reduce app concurrency quickly\nFor FastAPI services, gunicorn/uvicorn workers can multiply pools.\n1. Lower workers:\n- `WEB_CONCURRENCY=2`(temporary)\n```bash\nkubectl -n ecommerce-prod set env deploy/checkout-service WEB_CONCURRENCY=2\n```\n2. Lower async DB pool size:\n-`DB_POOL_SIZE=10`(default 30)\n-`DB_MAX_OVERFLOW=5`(default 20)\n\n## B) Enable pgbouncer (if disabled)\nWe run pgbouncer in transaction pooling mode.\n- Service DNS:`pgbouncer.ecommerce-prod.svc:6432`\n- Env var: `DATABASE_URL=postgresql+psycopg://...@pgbouncer:6432/app`\nIf a deploy pointed services at primary directly, revert.\n\n## C) Kill idle-in-transaction sessions (last resort)\nOnly after identifying offenders.\n```sql\nselect pg_terminate_backend(pid)\nfrom pg_stat_activity\nwhere state='idle in transaction' and now()-xact_start > interval '2 minutes';\n```\n\n## D) Protect primary\nIf saturation continues, apply rate limits to checkout endpoints and return 429.\n\n# Recovery\n- Connections drop below 70% of max\n- Error rate returns to baseline\n- Verify pgbouncer stats:\n```sql\nshow pools;\nshow stats;\n```\n\n# Edge cases\n- **Connection leaks**: if SQLAlchemy sessions are not closed on exception paths. Look for code changes around `async with session.begin()`.\n- **Background workers**: indexing-worker or refund-reconciler might have higher concurrency than web pods.\n- **Node service pooling**: payment-gateway uses `pg`module; ensure`max: 20`is set. Without it, Node can open unbounded connections under load.\n\n# Related\n- ADR-2024-08: Adopt pgbouncer transaction pooling\n- Checklist: CL-2025-09-prod-deploy (verify DB pool settings)\n"
    },
    {
      "doc_id": "kb-2024-12-adr-stripe-webhooks",
      "title": "ADR-2024-12: Stripe Webhooks as Source of Truth for Payment State",
      "document_type": "adr",
      "created_at": "2024-12-15",
      "content": "# Status\nAccepted\n\n# Context\nWe integrate Stripe for card payments and refunds. Historically, checkout-service polled Stripe for PaymentIntent status, which caused:\n- Increased API cost and throttling during traffic spikes\n- Race conditions when polling lagged behind actual status\n- Complex retry logic across services\n\nWe already have a legacy Node **payment-gateway** that receives Stripe webhook events, but its handler was previously treated as best-effort and not authoritative.\n\n# Decision\nMake **Stripe webhooks** the authoritative source of payment state. Specifically:\n- **payment-gateway** will validate webhook signatures and persist raw event payloads (minimally) in Postgres`stripe_events`.\n- **checkout-service** will update `payments.payment_status`based on processed events only.\n- Polling will remain as a fallback only for reconciliation jobs (daily) and for manual support tools.\n\n# Technical details\n## Stripe API version\nPin Stripe API version in payment-gateway to`2023-10-16`to keep event shape stable.\n\n## Webhook endpoint\n- Route:`POST /webhooks/stripe`\n- Must use raw body to validate signature.\n\n## Signature verification\n- Env var: `STRIPE_WEBHOOK_SECRET`\n- Reject if signature invalid. Log sample:\n  - `StripeSignatureVerificationError: No signatures found matching the expected signature`\n\n## Idempotency\n- Store `event.id`(e.g.,`evt*...`) in `stripe_events.event_id`(unique).\n- Before processing, check existence.\n\n## Processing pipeline\n1. Receive event and persist to`stripe_events`.\n2. Enqueue internal job `process_stripe_event(event_id)`.\n3. Update `payments`and`orders`tables in a transaction.\n\nSchema (proposed):\n```sql\ncreate table stripe_events (\n  event_id text primary key,\n  type text not null,\n  created_at timestamptz not null default now(),\n  payload jsonb not null,\n  processed_at timestamptz\n);\n```\n\n# Consequences\n## Positive\n- Lower Stripe API usage and fewer throttling errors\n- Single consistent state transition mechanism\n- Better auditability (raw events stored)\n\n## Negative / risks\n- If webhook handler breaks, payment state stalls (orders remain pending).\n- Requires strict operational runbook (see RB-2026-01 stripe webhook backlog).\n- Event order is not guaranteed; code must handle out-of-order events.\n\n# Alternatives considered\n## A) Continue polling\nRejected due to cost and complexity.\n\n## B) Stripe events to Kafka\nDeferred. Would add infrastructure and operational overhead; revisit when we migrate payment-gateway to Python.\n\n# Notes\nThis ADR assumes Postgres availability for event persistence. If Postgres is down, payment-gateway should return 500 to force Stripe retries (do not ack without persistence).\n"
    },
    {
      "doc_id": "kb-2025-03-adr-redis-cart-cache",
      "title": "ADR-2025-03: Redis as Primary Cache for Carts (LFU eviction policy)",
      "document_type": "adr",
      "created_at": "2025-03-11",
      "content": "# Status\nAccepted\n\n# Context\nCart reads are among our highest QPS endpoints. Postgres load during peak sales events led to elevated p95 (> 450ms) on cart-service. We need a low-latency cache, and we already operate Redis.\n\nWe previously cached carts in-process, but:\n- Pods scale horizontally, cache warmup is inconsistent\n- Deploys flush in-process caches\n- Memory usage was unpredictable\n\n# Decision\nUse Redis as the primary cache for cart payloads in **cart-service**, with Postgres as the source of truth.\n- Cache key format:`cart:{user_id}:v`\n- Cache TTL: 900 seconds\n- Eviction policy: `allkeys-lfu`\n- Payload: msgpack-encoded cart model (v2)\n\n# Technical details\n## Redis config\nBaseline config snippet:\n```conf\nmaxmemory 18gb\nmaxmemory-policy allkeys-lfu\nactivedefrag yes\ntimeout 0\n```\n\n## cart-service behavior\n1. Read-through cache:\n- GET `/api/cart/{user_id}`:\n  - Try Redis, if hit return cached cart.\n  - If miss, load from Postgres, write to Redis.\n2. Write-through on mutation:\n- POST `/api/cart/{user_id}/items`:\n  - Update Postgres transactionally.\n  - Publish event `cart.updated`.\n  - Update Redis key.\n\n## ETag / concurrency\ncheckout-service uses ETag for optimistic concurrency.\n- `ETag`derived from`cart.version`and item hashes.\n- Response header:`ETag: W/{etag}`\n\n## Failure mode\nIf Redis is unavailable:\n- Fall back to Postgres.\n- Set header `X-Cache: bypass`.\n\n# Consequences\n## Positive\n- Reduced Postgres load during peaks\n- Faster cart page loads\n\n## Negative / risks\n- Redis eviction under memory pressure can cause cache churn.\n- If ETag derivation depends on cached payload and keys are evicted, version mismatch behavior can worsen.\n\n# Alternatives\n## A) Store carts fully in Redis (source of truth)\nRejected: higher risk of data loss and complex durability.\n\n## B) Use Postgres only with aggressive indexing\nRejected: cost and limited latency improvement.\n\n# Follow-ups\n- Add alerting on Redis evictions.\n- Document incident response (see RB-2026-02 Redis evictions).\n\n# Note\nThis ADR prioritizes performance. If we observe eviction-driven incidents, we may need to revisit TTL, key size limits, or move to a smaller cached representation.\n"
    },
    {
      "doc_id": "kb-2025-02-adr-es-aliasing",
      "title": "ADR-2025-02: Elasticsearch Index Aliasing and Zero-Downtime Reindexing for Products",
      "document_type": "adr",
      "created_at": "2025-02-06",
      "content": "# Status\nAccepted\n\n# Context\nWe need to evolve product search mappings (new analyzers, fields) without downtime. Directly updating mappings is limited, and reindexing can take hours for 30M docs.\n\n# Decision\nAdopt an index aliasing strategy:\n- Write alias: `products_write`\n- Read alias: `products_read`\n- Concrete indices: `products-v3-YYYY.MM.DD`\n\nReindex flow:\n1. Create new index with updated template.\n2. Bulk reindex from Postgres snapshot (or existing index).\n3. Atomically switch read alias.\n4. Switch write alias after dual-write validation.\n\n# Technical details\n## Index templates\nTemplate name: `products-template-v3`\n- Dynamic mapping: disabled for `attributes.*`to avoid field explosion.\n-`total_fields.limit`: 1000\n\nExample template snippet:\n```json\n{\n  \"index_patterns\": [\"products-v3-*\"]\n}\n```\n\n## Dual write\nindexing-worker publishes to both old and new indices for 30 minutes.\n- Env var: `INDEX_DUAL_WRITE=true`\n\n## Aliasing commands\n```bash\ncurl -X POST localhost:9200/_aliases -H 'Content-Type: application/json' -d '{\n  \"actions\": [\n    {\"remove\": {\"alias\": \"products_read\", \"index\": \"products-v3-2025.01.30\"}},\n    {\"add\": {\"alias\": \"products_read\", \"index\": \"products-v3-2025.02.06\"}}\n  ]\n}'\n```\n\n# Consequences\n## Positive\n- Zero downtime mapping changes\n- Safer rollback (repoint alias)\n\n## Negative\n- Higher storage usage during reindex windows\n- Operational complexity during dual write\n\n# Alternatives\n- Use a single rolling index with ILM only: rejected; mapping changes still require reindex.\n\n# Edge cases\n- If a node is under disk watermark, alias switch won’t fix unassigned shards.\n- If search-api uses field names removed in new mapping, queries can fail with `failed to find field`.\n\n# References\n- Runbook: RB-2025-10 ES cluster red\n"
    },
    {
      "doc_id": "kb-2024-08-adr-pgbouncer",
      "title": "ADR-2024-08: Introduce PgBouncer Transaction Pooling for Postgres",
      "document_type": "adr",
      "created_at": "2024-08-22",
      "content": "# Status\nAccepted\n\n# Context\nWe operate multiple web services and workers, each with its own DB pool. Under load, the sum of pools exceeds Postgres capacity, resulting in incidents with `too many clients already`.\n\n# Decision\nAdopt PgBouncer in **transaction pooling** mode for all services.\n- Postgres remains primary.\n- Services connect to PgBouncer at port 6432.\n\n# Technical details\n## PgBouncer settings\n- `pool_mode = transaction`\n- `max_client_conn = 5000`\n- `default_pool_size = 50`\n- `reserve_pool_size = 10`\n- `server_idle_timeout = 60`\n\n## Service configuration\n- Replace direct DB host with `pgbouncer.ecommerce-prod.svc`\n- SQLAlchemy async:\n  - `pool_size=10`\n  - `max_overflow=5`\n\n## Limitations\nTransaction pooling breaks session-level features:\n- prepared statements\n- temp tables across transactions\n- session settings (must be set per transaction)\n\nFor services requiring session features (rare), we allow direct connections behind an exception process.\n\n# Consequences\n- Lower connection pressure on Postgres\n- Additional operational component (PgBouncer)\n\n# Rollout plan\n1. Deploy PgBouncer and validate health.\n2. Migrate services one by one.\n3. Add alert on Postgres connection usage.\n\n# Edge cases\n- Node payment-gateway must disable statement-level prepared queries if it assumes session pooling.\n- Alembic migrations should run against primary Postgres, not PgBouncer.\n\n# References\n- Runbook: RB-2024-11 Postgres connection exhaustion\n"
    },
    {
      "doc_id": "kb-2026-01-onboarding-fastapi-services",
      "title": "Onboarding Guide: Working on FastAPI Microservices (checkout-service, cart-service, search-api)",
      "document_type": "onboarding",
      "created_at": "2026-01-05",
      "content": "# Overview\nThis guide gets you from zero to running our core FastAPI services locally with Docker and a minimal Kubernetes dev setup.\n\n# Repos and services\n- `checkout-service/`(Python 3.11, FastAPI 0.110)\n-`cart-service/`(Python 3.11)\n-`search-api/`(Python 3.11)\n-`infra/`(docker-compose, k8s manifests)\n- Legacy:`payment-gateway/`(Node 18)\n\n# Local prerequisites\n- Docker Desktop 4.27+\n- Python 3.11.7\n- Poetry 1.8+\n- kubectl 1.29+\n\n# Quick start (docker-compose)\nFrom`infra/`:\n```bash\ndocker compose up -d postgres redis elasticsearch\n```\nDefaults:\n- Postgres: `localhost:5432`, db `ecommerce`, user `app`, password `app`\n- Redis: `localhost:6379`\n- Elasticsearch: `localhost:9200`(single-node)\n\n# Running checkout-service\n```bash\ncd checkout-service\npoetry install\nexport DATABASE_URL=postgresql+psycopg://app:app@localhost:5432/ecommerce\nexport REDIS_URL=redis://localhost:6379/0\npoetry run uvicorn app.main:app --reload --port 8081\n```\nHealth endpoints:\n-`/health/live`\n- `/health/ready`\n\nCommon startup errors:\n- Missing env var:\n  - `pydantic_core._pydantic_core.ValidationError: Settings.STRIPE_API_KEY Field required`\n- Wrong DB URL:\n  - `psycopg.OperationalError: connection failed: Connection refused`\n\n# DB migrations\nWe use Alembic.\n```bash\ncd checkout-service\npoetry run alembic upgrade head\n```\nRule: migrations run against **primary Postgres**, not PgBouncer.\n\n# Running cart-service\n```bash\ncd cart-service\npoetry install\nexport CART_CACHE_TTL_SECONDS=900\npoetry run uvicorn app.main:app --reload --port 8082\n```\nEdge case: if Redis is down and `READINESS_STRICT_DEPS=true`, readiness fails. For local dev, set `READINESS_STRICT_DEPS=false`.\n\n# Running search-api\n```bash\ncd search-api\npoetry install\nexport ELASTICSEARCH_URL=http://localhost:9200\npoetry run uvicorn app.main:app --reload --port 8083\n```\nIf you see:\n- `failed to find field`errors: your local ES index mapping is stale. Recreate:\n```bash\ncurl -X DELETE http://localhost:9200/products-v3-local\npython scripts/create_index.py\n```\n\n# Testing\n- Unit tests:`poetry run pytest -q`\n- Integration tests require docker-compose dependencies.\n\n# Internal conventions\n- Service names in logs: `service=<name> env=<env> commit=<sha>`\n- Error responses:\n  - JSON: `{ 'error_code': '...', 'message': '...' }`\n- Timeouts:\n  - All outbound calls must set connect + read timeouts.\n\n# Debugging tips\n- Use `X-Request-Id`header; services propagate it.\n- For DB issues, check`application_name` in Postgres (`checkout-service@local`).\n- For Redis cache behavior, set `LOG_CACHE_KEYS=true`in cart-service (do not enable in prod).\n\n# Next steps\n- Read runbooks: RB-2026-02 Redis evictions, RB-2026-01 Stripe webhook backlog\n- Read ADRs: ADR-2025-03 Redis cart cache, ADR-2024-12 Stripe webhooks\n"
    },
    {
      "doc_id": "kb-2025-04-onboarding-payments",
      "title": "Onboarding Guide: Payments Flow (Stripe, payment-gateway, checkout-service)",
      "document_type": "onboarding",
      "created_at": "2025-04-03",
      "content": "# Overview\nPayments touch multiple services and have strict idempotency and audit requirements. This guide explains the current flow, common pitfalls, and how to test safely.\n\n# Services\n- **checkout-service** (creates orders, initiates payment intents)\n- **payment-gateway** (Node legacy; owns Stripe keys and webhook ingestion)\n- **refund-reconciler** (cronjob; reconciles refunds daily)\n\n# Data model (Postgres)\nKey tables:\n-`orders(id, status, total_amount, currency, created_at)`\n- `payments(id, order_id, provider, payment_status, stripe_payment_intent_id, stripe_event_id)`\n- `stripe_events(event_id, type, payload, processed_at)`\n\nConstraints:\n- `payments.stripe_event_id`has a unique index (prevents double-processing)\n\n# Happy path\n1. Client calls checkout-service:\n-`POST /api/checkout/start`\n2. checkout-service requests payment intent creation from payment-gateway:\n- internal endpoint: `POST /internal/stripe/payment_intents`\n3. payment-gateway creates PaymentIntent in Stripe (API version 2023-10-16).\n4. Client confirms payment via Stripe client SDK.\n5. Stripe sends webhook `payment_intent.succeeded`.\n6. payment-gateway persists event, enqueues processing.\n7. checkout-service updates payment/order state.\n\n# Local testing\n## Stripe CLI\nUse Stripe CLI to forward webhooks to local payment-gateway:\n```bash\nstripe listen --forward-to localhost:8090/webhooks/stripe\n```\nSet env:\n- `STRIPE_WEBHOOK_SECRET`from Stripe CLI output.\n\n## Common local failure\nIf you see`invalid_signature`, ensure the webhook route uses raw body parsing.\n\n# Idempotency rules\n- Stripe events are at-least-once.\n- All handlers must tolerate duplicates and out-of-order delivery.\n\nWe use:\n- Postgres uniqueness on event id\n- Redis TTL key: `stripe:evt:{event_id}`(7 days)\n\n# Operational notes\n- If Postgres is down, payment-gateway should not ack webhooks.\n- If Redis is down, we still rely on Postgres unique constraint (slower but correct).\n\n# Edge cases\n- Partial refunds: multiple`charge.refunded`events can occur.\n- Currency mismatch: Stripe may return amounts in minor units; ensure rounding is consistent.\n- 3DS flows:`requires_action`state can last minutes.\n\n# Where to look when things break\n- Runbook: RB-2026-01 Stripe webhook backlog\n- Postmortem: PM-2025-08 duplicate fulfillment\n- ADR: ADR-2024-12 Stripe webhooks source of truth\n"
    },
    {
      "doc_id": "kb-2024-09-onboarding-k8s-and-ci",
      "title": "Onboarding Guide: CI/CD and Kubernetes Basics for This Platform",
      "document_type": "onboarding",
      "created_at": "2024-09-14",
      "content": "# Overview\nThis guide covers how we build, test, and deploy services using GitHub Actions, Docker, and Kubernetes.\n\n# CI: GitHub Actions\nEach service has`.github/workflows/ci.yml`with jobs:\n-`lint`(ruff 0.4.x)\n-`test`(pytest)\n-`build`(docker buildx)\n-`push`(container registry)\n\nConventions:\n- Image tag:`<service>:<git-sha>`\n- Release tag: `<service>:v<semver>`\n\n# Deployment flow\n- Merges to `main`deploy to staging.\n- Manual promotion to prod via workflow`promote.yml`.\n\n# Kubernetes namespaces\n- `ecommerce-staging`\n- `ecommerce-prod`\n\n# Common kubectl commands\n- Rollout status:\n```bash\nkubectl -n ecommerce-prod rollout status deploy/cart-service\n```\n- Events:\n```bash\nkubectl -n ecommerce-prod get events --sort-by=.metadata.creationTimestamp | tail -n 50\n```\n\n# Config and secrets\n- ConfigMaps: non-sensitive config.\n- Secrets: Stripe keys, DB passwords.\n\nCommon failure:\n- Missing secret key -> pydantic validation errors at startup.\n\n# Observability\n- Prometheus scrapes `/metrics`.\n- Grafana dashboards are grouped by service.\n\n# Edge cases\n- Readiness probes can block rollout even if service is healthy locally.\n- If you accidentally point migrations at PgBouncer, you can get confusing errors.\n\n# Related docs\n- Runbook: RB-2025-06 rollout stuck\n- Checklist: CL-2025-09 prod deploy\n"
    },
    {
      "doc_id": "kb-2025-11-api-cart-service",
      "title": "API Spec: cart-service Public API (v1)",
      "document_type": "api_spec",
      "created_at": "2025-11-02",
      "content": "# Overview\ncart-service owns cart state and exposes endpoints for reading and mutating carts. Postgres is the source of truth; Redis is a performance cache (see ADR-2025-03).\n\nBase URL: `/api/cart`\nAuth: bearer token, required for all endpoints.\nIdempotency: mutation endpoints accept `Idempotency-Key`header.\n\n# Models\n## Cart\n-`cart_id`(uuid)\n-`user_id`(uuid)\n-`version`(int)\n-`items`(list)\n-`currency`(string)\n-`updated_at`(RFC3339)\n\n## CartItem\n-`sku`(string)\n-`qty`(int, 1..99)\n-`unit_price_minor`(int)\n\n# Endpoints\n## GET /api/cart/{user_id}\nReturns the current cart.\n\nHeaders:\n- Optional:`If-None-Match`(ETag)\n\nResponses:\n- 200: cart payload\n- 304: not modified\n- 404:`{ 'error_code': 'CART_NOT_FOUND' }`\n\nExample response:\n```json\n{\n  \"cart_id\": \"3b3b6f9e-0f2e-4f0c-9d8a-1b2a3c4d5e6f\",\n  \"user_id\": \"9a9a...\",\n  \"version\": 17,\n  \"currency\": \"USD\",\n  \"items\": [{\"sku\": \"SKU-123\", \"qty\": 2, \"unit_price_minor\": 1299}],\n  \"updated_at\": \"2025-11-02T10:12:30Z\"\n}\n```\n\n## POST /api/cart/{user_id}/items\nAdds or updates an item.\n\nHeaders:\n- `Idempotency-Key: <uuid>`\n- `If-Match: <etag>`(required)\n\nRequest:\n```json\n{ \"sku\": \"SKU-123\", \"qty\": 3 }\n```\n\nResponses:\n- 200: updated cart\n- 409:`{ 'error_code': 'CART_VERSION_MISMATCH' }`\n- 412: `{ 'error_code': 'PRECONDITION_FAILED' }`(missing/invalid If-Match)\n- 422:`{ 'error_code': 'INVALID_QTY' }`\n\nEdge cases:\n- qty 0 is rejected (use DELETE endpoint).\n- large carts (>200 items) may exceed payload size limits; clients should paginate using `GET /api/cart/{user_id}/items?cursor=...`(internal-only).\n\n## DELETE /api/cart/{user_id}/items/{sku}\nRemoves an item.\n\nResponses:\n- 200: updated cart\n- 404:`{ 'error_code': 'ITEM_NOT_FOUND' }`\n\n# Caching headers\n- cart-service returns:\n  - `ETag: W/<hash>`\n  - `Cache-Control: private, max-age=0`\n\n# Error format\nAll errors:\n```json\n{ \"error_code\": \"...\", \"message\": \"...\", \"request_id\": \"...\" }\n```\n\n# Operational notes\n- If Redis is unavailable, `X-Cache: bypass`is set.\n- If Redis evictions spike, users may see more 409s (see RB-2026-02).\n"
    },
    {
      "doc_id": "kb-2025-09-api-checkout-service",
      "title": "API Spec: checkout-service Public API (v2)",
      "document_type": "api_spec",
      "created_at": "2025-09-19",
      "content": "# Overview\ncheckout-service orchestrates checkout, order creation, and payment initiation via payment-gateway.\n\nBase URL:`/api/checkout`\nAuth: bearer token.\nIdempotency: required for order creation.\n\n# Endpoints\n## POST /api/checkout/start\nCreates an order draft and returns a payment intent client secret.\n\nHeaders:\n- `Idempotency-Key: <uuid>`\n\nRequest:\n```json\n{ \"user_id\": \"...\", \"cart_id\": \"...\", \"shipping_address_id\": \"...\" }\n```\n\nResponses:\n- 201:\n```json\n{ \"order_id\": \"...\", \"status\": \"PAYMENT_PENDING\", \"stripe_client_secret\": \"pi_..._secret_...\" }\n```\n- 409: `{ 'error_code': 'CART_VERSION_MISMATCH' }`\n- 422: `{ 'error_code': 'ADDRESS_INVALID' }`\n- 503: `{ 'error_code': 'PAYMENT_PROVIDER_UNAVAILABLE' }`\n\nEdge cases:\n- If cart-service returns 304 (not modified), checkout-service must still fetch cart totals from persisted snapshot to avoid mismatch.\n- If payment-gateway times out but Stripe created the intent, idempotency key must map to the same intent.\n\n## GET /api/checkout/orders/{order_id}\nReturns order status.\n\nResponses:\n- 200: order payload\n- 404: `{ 'error_code': 'ORDER_NOT_FOUND' }`\n\n## POST /api/checkout/orders/{order_id}/cancel\nCancels an unpaid order.\n\nResponses:\n- 200: cancelled\n- 409: `{ 'error_code': 'ORDER_ALREADY_PAID' }`\n\n# State machine\n- `DRAFT`->`PAYMENT_PENDING`->`PAID`->`FULFILLING`->`FULFILLED`\n- Failures:\n  - `PAYMENT_FAILED`\n  - `CANCELLED`\n\n# Error codes\n- `PAYMENT_PENDING_TIMEOUT`(order stuck > 10 minutes)\n-`PAYMENT_EVENT_DUPLICATE`(Stripe event already processed)\n\n# Observability\n-`checkout_start_total{status}`\n- `checkout_payment_pending_total`\n\n# Related docs\n- ADR-2024-12 Stripe webhooks\n- Runbook: RB-2026-01 Stripe webhook backlog\n"
    },
    {
      "doc_id": "kb-2025-05-api-search-api",
      "title": "API Spec: search-api Public API (v3) for Product Search",
      "document_type": "api_spec",
      "created_at": "2025-05-28",
      "content": "# Overview\nsearch-api provides product search backed by Elasticsearch. It exposes a stable query interface even as index mappings evolve (see ADR-2025-02).\n\nBase URL: `/api/search`\nAuth: optional for anonymous search; required for personalized boosts.\n\n# Endpoint\n## GET /api/search/products\nQuery params:\n- `q`(string)\n-`page`(int, default 1)\n-`page_size`(int, default 24, max 100)\n-`filters`(repeatable, e.g.,`brand:acme`)\n- `sort` (`relevance|price_asc|price_desc`)\n\nResponse 200:\n```json\n{\n  \"total\": 1234,\n  \"page\": 1,\n  \"page_size\": 24,\n  \"results\": [{\"sku\": \"SKU-123\", \"title\": \"...\", \"price_minor\": 1299}]\n}\n```\n\nErrors:\n- 400: `{ 'error_code': 'INVALID_FILTER' }`\n- 503: `{ 'error_code': 'SEARCH_UNAVAILABLE' }`\n\n# Timeouts and retries\n- search-api sets ES request timeout 150ms.\n- Retries are disabled to avoid amplifying load.\n\n# Edge cases\n- `q`empty: returns trending products (cached for 60s).\n- If ES returns 429`es_rejected_execution_exception`, search-api returns 503 with `retry_after_seconds: 2`.\n- If index alias missing (misconfig), error:\n  - `index_not_found_exception: no such index [products_read]`\n\n# Operational notes\n- Read alias: `products_read`\n- If cluster health is red, enable degraded mode:\n  - `SEARCH_ENABLE_AGGS=false`\n\n# Related docs\n- Runbook: RB-2025-10 ES cluster red\n- Postmortem: PM-2025-12 ES disk watermark incident\n"
    },
    {
      "doc_id": "kb-2025-11-postmortem-redis-oom",
      "title": "Postmortem: Redis OOM and Evictions Broke Checkout Consistency",
      "document_type": "postmortem",
      "created_at": "2025-11-30",
      "content": "# Incident summary\nOn 2025-11-29, Redis experienced sustained memory pressure leading to OOM behavior and heavy evictions. cart-service cache churn caused a surge in cart version mismatches during checkout, reducing conversion.\n\n# Impact\n- Duration: 47 minutes (09:12–09:59 UTC)\n- 12.4% of checkout attempts failed with 409/412\n- Cart page latency increased from p95 120ms to 410ms\n\n# Timeline\n- 09:12: Alerts: `redis_evicted_keys`rising\n- 09:16: checkout-service error rate spikes (409)\n- 09:22: Oncall enables CART_CACHE_BYPASS\n- 09:31: Redis memory stabilizes after key cleanup\n- 09:45: Gradual re-enable cache\n- 09:59: Metrics return to baseline\n\n# Root cause\nA new feature in cart-service stored expanded recommendation payloads inside cart cache values (including 20 recommended SKUs with metadata). Average cart cache value size increased ~6x, exceeding the expected memory budget.\n\nRedis config at the time:\n-`maxmemory 18gb`\n- `maxmemory-policy allkeys-lfu`\n\nLFU helped, but the increase in value size caused:\n- rapid evictions under load\n- increased misses -> more Postgres reads\n- ETag derived inconsistently when cache keys were evicted and rehydrated concurrently\n\n# Contributing factors\n- Missing alert on average Redis value size for `cart:*`keys\n- Load test did not include Black Friday recommendation payload shape\n- checkout-service treated 409 as a hard failure rather than retrying with refreshed ETag\n\n# Detection\nPrometheus alerts fired:\n-`increase(redis_evicted_keys_total[5m]) > 0`\n- `http_409_total`for checkout-service\n\n# Resolution\n- Enabled`CART_CACHE_BYPASS=true`to stop dependency on Redis\n- Purged oversized cart keys\n- Deployed hotfix to store only recommendation SKUs, not full metadata\n\n# What went well\n- Oncall had a documented bypass flag\n- Rollout of env changes was quick\n\n# What went poorly\n- Redis issue cascaded into checkout failures\n- Purging keys caused temporary DB pressure\n\n# Action items\n1. Enforce max cart cache value size (hard cap 128KB); if exceeded, skip caching.\n2. Update checkout-service to retry once on`CART_VERSION_MISMATCH`by refetching cart.\n3. Add dashboards:\n- average value size by key prefix\n4. Revisit ADR-2025-03 assumptions: Redis as primary cache for carts increases coupling.\n\n# Related\n- Runbook: RB-2026-02 Redis evictions\n- ADR: ADR-2025-03 Redis cart cache\n"
    },
    {
      "doc_id": "kb-2025-07-postmortem-migrations-caused-outage",
      "title": "Postmortem: Checkout Outage Due to Unapplied Migrations After Deploy",
      "document_type": "postmortem",
      "created_at": "2025-07-09",
      "content": "# Incident summary\nOn 2025-07-08, checkout-service deployed version 2.14.0 which expected a new column`orders.payment_provider`. The migration job did not run due to a misconfigured GitHub Actions environment variable, causing startup crashes and a partial outage.\n\n# Impact\n- Duration: 23 minutes\n- 100% of requests to `/api/checkout/start`returned 500\n- Other services mostly unaffected\n\n# Timeline\n- 14:02 UTC: Deploy initiated\n- 14:04: Pods crashloop with`UndefinedColumn`\n- 14:06: Oncall identifies missing migration\n- 14:10: Rollback executed\n- 14:18: Migration job run manually\n- 14:25: Redeploy successful\n\n# Root cause\nThe GitHub Actions workflow `promote.yml`sets`RUN_MIGRATIONS=true`for prod. A refactor renamed the variable to`RUN_DB_MIGRATIONS`in the migration cronjob chart, but the workflow was not updated. Migration did not execute.\n\nError observed:\n-`psycopg.errors.UndefinedColumn: column orders.payment_provider does not exist`\n\n# Contributing factors\n- No pre-deploy check verifying schema head\n- Rollout allowed new pods to replace old pods quickly, removing healthy capacity\n\n# Resolution\n- Rollback checkout-service\n- Manual migration job:\n```bash\nkubectl -n ecommerce-prod create job --from=cronjob/checkout-migrations checkout-migrations-manual\n```\n- Re-deploy after verifying alembic head\n\n# Action items\n1. Add deploy checklist item: verify `alembic current`equals expected head.\n2. Enforce`maxUnavailable=0`for checkout-service to prevent total outage during crashloops.\n3. Add alert when migration job did not run during a deploy window.\n\n# Related\n- Runbook: RB-2025-06 rollout stuck\n- Checklist: CL-2025-09 prod deploy\n"
    },
    {
      "doc_id": "kb-2025-12-postmortem-es-disk-watermark",
      "title": "Postmortem: Elasticsearch Disk Watermark Caused Search Outage",
      "document_type": "postmortem",
      "created_at": "2025-12-18",
      "content": "# Incident summary\nOn 2025-12-17, Elasticsearch cluster entered red state due to disk watermark thresholds on two data nodes. Shards became unassigned, and search-api returned 503 for a significant portion of requests.\n\n# Impact\n- Duration: 1h 12m\n- 38% of search requests failed (503)\n- Indexing lag grew to 4.6M messages\n\n# Timeline\n- 08:41 UTC: Disk usage crosses high watermark\n- 08:47: Cluster status turns yellow\n- 09:02: Cluster status turns red; unassigned primaries\n- 09:05: Oncall disables aggregations and scales indexing-worker to 0\n- 09:18: Old indices deleted to free space\n- 09:31: Cluster returns to yellow, then green\n- 09:53: Indexing resumes with smaller bulk size\n\n# Root cause\nILM policy`products-ilm-v3`failed to delete old indices because the policy referenced an outdated index pattern after an aliasing change. As a result, indices older than 14 days accumulated.\n\n# Contributing factors\n- No alert on ILM failures\n- Bulk indexing size was 1000, causing high segment merge pressure\n- Disk autoscaling was disabled for cost reasons\n\n# Resolution\n- Manually deleted old indices\n- Fixed ILM pattern\n- Reduced`INDEXING_BULK_SIZE`to 250 temporarily\n\n# Action items\n1. Add alert on ILM errors and on disk watermark thresholds.\n2. Add a weekly operational checklist item to verify retention.\n3. Validate ADR-2025-02 aliasing rollout steps include ILM pattern updates.\n\n# Related\n- Runbook: RB-2025-10 ES cluster red\n- ADR: ADR-2025-02 ES aliasing\n"
    },
    {
      "doc_id": "kb-2025-09-checklist-prod-deploy",
      "title": "Operational Checklist: Production Deploy (FastAPI + Node services)",
      "document_type": "checklist",
      "created_at": "2025-09-01",
      "content": "# Purpose\nA short checklist to reduce common production deploy failures across checkout-service, cart-service, search-api, and payment-gateway.\n\n# Before deploy\n- [ ] Confirm current incident status: no ongoing SEV-1/SEV-2.\n- [ ] Check Postgres connections < 70% of max.\n- [ ] Check Redis evictions flat.\n- [ ] Check Elasticsearch health green.\n- [ ] Verify feature flags for rollout are documented in the PR.\n\n# Build and artifacts\n- [ ] GitHub Actions:`ci.yml`green.\n- [ ] Image tag exists in registry and matches commit SHA.\n- [ ] For payment-gateway, confirm Node runtime stays at 18.x (do not auto-bump).\n\n# Database\n- [ ] If schema changes:\n  - [ ] Ensure migration cronjob exists and uses primary Postgres (not PgBouncer).\n  - [ ] Verify alembic head in staging.\n\n# Config and secrets\n- [ ] Secrets present in namespace:\n  -`STRIPE_API_KEY`, `STRIPE_WEBHOOK_SECRET`(payment-gateway)\n- [ ] ConfigMap changes reviewed (timeouts, pool sizes).\n\n# Deploy execution\n- [ ] Deploy to staging first; run smoke tests:\n  -`/health/ready`on all services\n  - Basic checkout flow (start -> pending)\n  - Search query returns results\n- [ ] Promote to prod.\n- [ ] Watch rollout status:\n```bash\nkubectl -n ecommerce-prod rollout status deploy/checkout-service\n```\n\n# After deploy (15 minutes)\n- [ ] Error rate stable (no sustained 5xx).\n- [ ] p95 latency within 20% of baseline.\n- [ ] Stripe webhook success rate stable.\n- [ ] Elasticsearch indexing lag not increasing.\n\n# Edge case notes\n- If enabling new Redis cache behavior, watch`redis_evicted_keys`and cart 409s.\n- If changing search mappings, verify alias`products_read`points to expected index.\n\n# References\n- RB-2025-06 rollout stuck\n- PM-2025-07 migrations caused outage\n"
    },
    {
      "doc_id": "kb-2024-10-checklist-weekly-ops",
      "title": "Operational Checklist: Weekly Platform Ops (Cache, Search, Payments)",
      "document_type": "checklist",
      "created_at": "2024-10-05",
      "content": "# Purpose\nWeekly checks to catch slow-burn issues (retention failures, creeping connection usage, webhook drift) before they become incidents.\n\n# Redis\n- [ ] Check memory usage trend and eviction count.\n- [ ] Sample key sizes for`cart:*`and`stripe:*`prefixes.\n- [ ] Verify`maxmemory-policy`remains`allkeys-lfu`.\n\n# Postgres\n- [ ] Check connection usage and top application_name consumers.\n- [ ] Check for `idle in transaction`sessions.\n- [ ] Review slow queries > 500ms from logs.\n\n# Elasticsearch\n- [ ] Verify cluster health green.\n- [ ] Verify ILM policy`products-ilm-v3`is active and not erroring.\n- [ ] Confirm retention: no`products-v3-*`older than 14 days unless explicitly needed.\n\n# Stripe / payments\n- [ ] Stripe webhook endpoint success rate over last 7 days.\n- [ ] Confirm`STRIPE_WEBHOOK_SECRET`unchanged and deployed consistently.\n- [ ] Check backlog metric`stripe_webhook_queue_depth`.\n\n# Kubernetes\n- [ ] Review CrashLoopBackOff counts.\n- [ ] Ensure resource requests/limits are not drifting (especially checkout-service).\n\n# Notes\nIf any check shows concerning trend (e.g., ES disk rising, Redis value sizes increasing), create an ops ticket and link to the relevant runbook.\n"
    }
  ]
}